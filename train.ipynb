{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pandas -y\n",
    "%conda install scikit-learn -y\n",
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset:\n",
      "    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1   \n",
      "\n",
      "Heart Disease Dataset:\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   0       145   233    1        2      150      0      2.3      2   \n",
      "1   67    1   3       160   286    0        2      108      1      1.5      1   \n",
      "2   67    1   3       120   229    0        2      129      1      2.6      1   \n",
      "3   37    1   2       130   250    0        0      187      0      3.5      2   \n",
      "4   41    0   1       130   204    0        2      172      0      1.4      0   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     2       0  \n",
      "1   3     1       1  \n",
      "2   2     3       1  \n",
      "3   0     1       0  \n",
      "4   0     1       0   \n",
      "\n",
      "parkinsons Disease Dataset:\n",
      "    MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
      "0      119.992       157.302        74.997         0.00784           0.00007   \n",
      "1      122.400       148.650       113.819         0.00968           0.00008   \n",
      "2      116.682       131.111       111.555         0.01050           0.00009   \n",
      "3      116.676       137.871       111.366         0.00997           0.00009   \n",
      "4      116.014       141.781       110.655         0.01284           0.00011   \n",
      "\n",
      "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
      "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
      "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
      "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
      "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
      "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
      "\n",
      "   MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1  \\\n",
      "0   0.02971      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031   \n",
      "1   0.04368      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192   \n",
      "2   0.03590      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179   \n",
      "3   0.03772      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501   \n",
      "4   0.04465      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 22 columns] \n",
      "\n",
      "Missing Values:\n",
      "\n",
      "Diabetes:\n",
      " Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64 \n",
      "\n",
      "Heart:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64 \n",
      "\n",
      "parkinsons:\n",
      " MDVP:Fo(Hz)         0\n",
      "MDVP:Fhi(Hz)        0\n",
      "MDVP:Flo(Hz)        0\n",
      "MDVP:Jitter(%)      0\n",
      "MDVP:Jitter(Abs)    0\n",
      "MDVP:RAP            0\n",
      "MDVP:PPQ            0\n",
      "Jitter:DDP          0\n",
      "MDVP:Shimmer        0\n",
      "MDVP:Shimmer(dB)    0\n",
      "Shimmer:APQ3        0\n",
      "Shimmer:APQ5        0\n",
      "MDVP:APQ            0\n",
      "Shimmer:DDA         0\n",
      "NHR                 0\n",
      "HNR                 0\n",
      "RPDE                0\n",
      "DFA                 0\n",
      "spread1             0\n",
      "spread2             0\n",
      "D2                  0\n",
      "PPE                 0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "# Load datasets\n",
    "diabetes = pd.read_csv(\"datasets/diabetes.csv\")\n",
    "heart = pd.read_csv(\"datasets/heart_disease.csv\")\n",
    "parkinsonsv2 = pd.read_csv(\"datasets/parkinsons.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Diabetes Dataset:\\n\", diabetes.head(), \"\\n\")\n",
    "print(\"Heart Disease Dataset:\\n\", heart.head(), \"\\n\")\n",
    "print(\"parkinsons Disease Dataset:\\n\", parkinsons.head(), \"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\")\n",
    "print(\"Diabetes:\\n\", diabetes.isnull().sum(), \"\\n\")\n",
    "print(\"Heart:\\n\", heart.isnull().sum(), \"\\n\")\n",
    "print(\"parkinsons:\\n\", parkinsons.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Drop non-feature columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['status'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes, scaler_diabetes = preprocess_data(diabetes, \u001b[33m\"\u001b[39m\u001b[33mOutcome\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m X_train_heart, X_test_heart, y_train_heart, y_test_heart, scaler_heart = preprocess_data(heart, \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons, scaler_parkinsons = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparkinsons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstatus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessing complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(df, target_column)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_data\u001b[39m(df, target_column):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[32m      6\u001b[39m     y = df[target_column]  \u001b[38;5;66;03m# Target (labels)\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Convert categorical columns to numeric using Label Encoding\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['status'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column])  # Features\n",
    "    y = df[target_column]  # Target (labels)\n",
    "\n",
    "    # Convert categorical columns to numeric using Label Encoding\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':  # If column is categorical\n",
    "            X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split into train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Run preprocessing again\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes, scaler_diabetes = preprocess_data(diabetes, \"Outcome\")\n",
    "X_train_heart, X_test_heart, y_train_heart, y_test_heart, scaler_heart = preprocess_data(heart, \"target\")\n",
    "X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons, scaler_parkinsons = preprocess_data(parkinsons, \"status\")\n",
    "\n",
    "print(\"Preprocessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Model Accuracy: 0.7532\n",
      "Heart Disease Model Accuracy: 0.8852\n",
      "Parkinson's Model Accuracy: 0.8974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, disease_name):\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{disease_name} Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train models for each dataset\n",
    "model_diabetes = train_and_evaluate(X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes, \"Diabetes\")\n",
    "model_heart = train_and_evaluate(X_train_heart, X_test_heart, y_train_heart, y_test_heart, \"Heart Disease\")\n",
    "model_parkinsons = train_and_evaluate(X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons, \"Parkinson's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete and scalers saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "def preprocess_data(df, target_column, scaler_path, encoder_path):\n",
    "    X = df.drop(columns=[target_column])  # Features\n",
    "    y = df[target_column]  # Target (labels)\n",
    "\n",
    "    # Convert categorical columns to numeric using Label Encoding\n",
    "    encoders = {}\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':  # If column is categorical\n",
    "            encoders[col] = LabelEncoder()\n",
    "            X[col] = encoders[col].fit_transform(X[col])\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split into train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Save scaler and encoders\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    joblib.dump(encoders, encoder_path)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Run preprocessing and save scalers\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = preprocess_data(\n",
    "    diabetes, \"Outcome\", \"Models/diabetes_scaler.pkl\", \"Models/diabetes_encoders.pkl\"\n",
    ")\n",
    "X_train_heart, X_test_heart, y_train_heart, y_test_heart = preprocess_data(\n",
    "    heart, \"target\", \"Models/heart_scaler.pkl\", \"Models/heart_encoders.pkl\"\n",
    ")\n",
    "X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons = preprocess_data(\n",
    "    parkinsons, \"status\", \"Models/parkinsons_scaler.pkl\", \"Models/parkinsons_encoders.pkl\"\n",
    ")\n",
    "\n",
    "print(\"Preprocessing complete and scalers saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save trained models\n",
    "# Save trained models\n",
    "joblib.dump(model_diabetes, 'Models/diabetes_model.pkl')\n",
    "joblib.dump(model_heart, 'Models/heart_model.pkl')\n",
    "joblib.dump(model_parkinsons, 'Models/parkinsons_model.pkl')\n",
    "\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd   #TESTTSTS\n",
    "import joblib\n",
    "\n",
    "# Load model and scaler\n",
    "model_diabetes = joblib.load('Models/diabetes_model.pkl')\n",
    "scaler_diabetes = joblib.load('Models/diabetes_scaler.pkl')\n",
    "\n",
    "# Define feature names (use the same column names from training data)\n",
    "feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "                 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Test with non-diabetic values\n",
    "test_input = np.array([[0, 85, 70, 20, 80, 22.0, 0.2, 25]])  # Example input\n",
    "\n",
    "# Convert to DataFrame to keep column names\n",
    "test_input_df = pd.DataFrame(test_input, columns=feature_names)\n",
    "\n",
    "# Scale the test input\n",
    "test_input_scaled = scaler_diabetes.transform(test_input_df)  # Now using DataFrame\n",
    "\n",
    "# Make prediction\n",
    "prediction = model_diabetes.predict(test_input_scaled)\n",
    "\n",
    "print(\"Prediction:\", prediction)  # Now it should work without the warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Feature Names: ['name' 'MDVP:Fo(Hz)' 'MDVP:Fhi(Hz)' 'MDVP:Flo(Hz)' 'MDVP:Jitter(%)'\n",
      " 'MDVP:Jitter(Abs)' 'MDVP:RAP' 'MDVP:PPQ' 'Jitter:DDP' 'MDVP:Shimmer'\n",
      " 'MDVP:Shimmer(dB)' 'Shimmer:APQ3' 'Shimmer:APQ5' 'MDVP:APQ' 'Shimmer:DDA'\n",
      " 'NHR' 'HNR' 'RPDE' 'DFA' 'spread1' 'spread2' 'D2' 'PPE']\n"
     ]
    }
   ],
   "source": [
    "# Check feature names in the dataset\n",
    "import joblib\n",
    "\n",
    "scaler_parkinsons = joblib.load('Models/parkinsons_scaler.pkl')\n",
    "\n",
    "# Get expected feature names\n",
    "expected_features = scaler_parkinsons.feature_names_in_\n",
    "print(\"Expected Feature Names:\", expected_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
